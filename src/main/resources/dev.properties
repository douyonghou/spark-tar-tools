deploy.type=dev

# spark.driver内存
spark.driver.memory=1g
# spark.executor的核数,官网推荐4~5个
spark.executor.cores=4
# spark.executor内存,大概1个yarn节点总内存/excuter数,具体还需要结合job的数据集以及划分并行度情况设定
spark.executor.memory=4g
# executor堆外内存
spark.yarn.executor.memoryOverhead=1g
# spark在clent模式提交下的内存
spark.yarn.am.memory=1g
# spark在clent模式提交下的核数
spark.yarn.am.cores=4
# 序列化
spark.serializer=org.apache.spark.serializer.KryoSerializer
# 序列化缓冲大小
spark.KryoSerializer.buffer=256k
# 在内存中缓存时压缩
spark.sql.inMemoryColumnarStorage.compressed=true
# 两个dataframe非常大,可能会用更多时间,默认是300
spark.sql.broadcastTimeout=36000
# 上传到hdfs的副本数
spark.yarn.submit.file.replication=3
# Spark应用程序主设备心跳到YARN ResourceManager中的时间间隔（以毫秒为单位）。该值的上限为YARN配置值的一半
spark.yarn.scheduler.heartbeat.interval-ms=3000
# 当存在挂起的容器分配请求时，Spark应用程序主服务器急切地向YARN ResourceManager发出心跳的初始时间间隔。不得大于 spark.yarn.scheduler.heartbeat.interval-ms。如果仍存在挂起的容器，spark.yarn.scheduler.heartbeat.interval-ms则分配间隔将在连续的紧急心跳中加倍，直到达到为止 。
spark.yarn.scheduler.initial-allocation.interval=200ms


